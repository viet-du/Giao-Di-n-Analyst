# app_improved.py
import logging
import os
import re
import sqlite3
import threading
import tkinter as tk
from datetime import datetime
from tkinter import ttk, filedialog, messagebox
import json
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import requests
import unicodedata
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import csv

# L·ª±a ch·ªçn th∆∞ vi·ªán mchien learning
try:
    from sklearn.linear_model import LinearRegression

    SKLEARN_OK = True
except Exception:
    SKLEARN_OK = False

# Optional PDF export
try:
    from fpdf import FPDF

    FPDF_OK = True
except Exception:
    FPDF_OK = False

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')
log = logging.getLogger("TikiApp")

# App globals
APP_TITLE = "Ph·∫ßn m·ªÅm tr·ª±c quan h√≥a d·ªØ li·ªáu + D·ª± ƒëo√°n"
df_global = pd.DataFrame()
processed_df = pd.DataFrame()
DB_FILES = []  # Thay ƒë·ªïi t·ª´ DB_FILE sang DB_FILES (danh s√°ch)
fig_global = None
current_fig = None

# Thi·∫øt l·∫≠p font ti·∫øng Vi·ªát cho matplotlib
try:
    # Th·ª≠ s·ª≠ d·ª•ng font Arial Unicode MS n·∫øu c√≥
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans', 'Arial']
    plt.rcParams['axes.unicode_minus'] = False
except:
    pass


# ---------------- Helpers ----------------
def sanitize_table_name(name):
    base = os.path.splitext(os.path.basename(name))[0]
    s = re.sub(r'[^0-9a-zA-Z_]', '_', base)
    if re.match(r'^\d', s):
        s = 't_' + s
    return s.lower()


def show_message(msg, title="Th√¥ng b√°o"):
    messagebox.showinfo(title, msg)


def show_error(msg, title="L·ªói"):
    messagebox.showerror(title, msg)


def ensure_db_files():
    global DB_FILES
    if not DB_FILES:
        base_dir = os.getcwd()
        default_db = os.path.join(base_dir, "tiki_data.db")
        if os.path.exists(default_db):
            DB_FILES = [default_db]
            try:
                listbox_dbs.delete(0, tk.END)
                for db_file in DB_FILES:
                    listbox_dbs.insert(tk.END, db_file)
            except Exception:
                pass


def extract_id(link):
    """Try to extract product id from tiki url query 'spid' or last numeric token."""
    if not isinstance(link, str):
        return None
    m = re.search(r'spid=(\d+)', link)
    if m:
        return m.group(1)
    # fallback: last numeric sequence
    m2 = re.findall(r'(\d+)', link)
    return m2[-1] if m2 else None


# ---------------- TIKI CRAWL ----------------
def build_tiki_link(p):
    product_id = p.get("id") or p.get('product_id')
    url_path = p.get("url_path") or p.get('url_key')
    if product_id and url_path:
        return f"https://tiki.vn/{url_path}?spid={product_id}"
    return p.get("url") or p.get('link') or 'N/A'


def crawl_tiki(category_id=1686, limit=50):
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "application/json, text/plain, */*"
    }
    url = f"https://tiki.vn/api/personalish/v1/blocks/listings?limit={limit}&page=1&category={category_id}"
    log.info("Requesting %s", url)
    resp = requests.get(url, headers=headers, timeout=25)
    if resp.status_code != 200:
        raise RuntimeError(f"API l·ªói: {resp.status_code}")

    data = resp.json()
    products = data.get("data", [])
    rows = []
    today = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    for p in products:
        name = (p.get("name") or "N/A").strip()
        price = p.get("price") or 0
        original_price = p.get("original_price") or p.get("list_price") or price
        discount = p.get("discount_rate") or 0
        qty = p.get("quantity_sold", {}).get("value", 0) if isinstance(p.get("quantity_sold"), dict) else (
                p.get("qty") or 0)
        link = build_tiki_link(p)
        rows.append([name, price, original_price, discount, qty, link, today])

    df = pd.DataFrame(rows, columns=["T√™n s·∫£n ph·∫©m", "Gi√°", "Gi√° g·ªëc", "Gi·∫£m gi√° (%)", "ƒê√£ b√°n", "Link", "Ng√†y crawl"])
    fname = f"tiki_products_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    df.to_csv(fname, index=False, encoding='utf-8-sig')
    log.info("Saved CSV %s", fname)

    # ch·ªâ n·∫°p v√†o df_global
    df_global_update(df)
    return df

def action_crawl_dialog():
    dlg = tk.Toplevel(root)
    dlg.title("Crawl Tiki - Tham s·ªë")
    dlg.geometry("400x200")
    dlg.resizable(False, False)
    dlg.transient(root)
    dlg.grab_set()

    # Center the dialog
    dlg.update_idletasks()
    x = root.winfo_x() + (root.winfo_width() - dlg.winfo_width()) // 2
    y = root.winfo_y() + (root.winfo_height() - dlg.winfo_height()) // 2
    dlg.geometry(f"+{x}+{y}")

    tk.Label(dlg, text="Category ID:").grid(row=0, column=0, padx=6, pady=6, sticky="w")
    ent_cat = tk.Entry(dlg, width=30)
    ent_cat.grid(row=0, column=1, padx=6, pady=6)
    ent_cat.insert(0, "8322")

    tk.Label(dlg, text="Limit (max items):").grid(row=1, column=0, padx=6, pady=6, sticky="w")
    ent_lim = tk.Entry(dlg, width=30)
    ent_lim.grid(row=1, column=1, padx=6, pady=6)
    ent_lim.insert(0, "50")

    var_append = tk.IntVar(value=1)
    chk = tk.Checkbutton(dlg, text="Append to DB (don't overwrite)", variable=var_append)
    chk.grid(row=2, column=0, columnspan=2, padx=6, pady=6, sticky="w")

    button_frame = tk.Frame(dlg)
    button_frame.grid(row=3, column=0, columnspan=2, pady=10)

    def go():
        cat = ent_cat.get().strip()
        try:
            lim = int(ent_lim.get().strip() or 50)
        except Exception:
            lim = 50
        append_db = bool(var_append.get())
        dlg.destroy()

        # Hi·ªÉn th·ªã th√¥ng b√°o ƒëang x·ª≠ l√Ω
        progress = tk.Toplevel(root)
        progress.title("ƒêang x·ª≠ l√Ω")
        progress.geometry("300x100")
        progress.transient(root)
        progress.grab_set()

        # Center the progress dialog
        progress.update_idletasks()
        x = root.winfo_x() + (root.winfo_width() - progress.winfo_width()) // 2
        y = root.winfo_y() + (root.winfo_height() - progress.winfo_height()) // 2
        progress.geometry(f"+{x}+{y}")

        tk.Label(progress, text="ƒêang crawl d·ªØ li·ªáu t·ª´ Tiki...").pack(pady=20)
        progress.update()

        def worker():
            try:
                # REMOVED: append_db parameter from crawl_tiki call
                df = crawl_tiki(category_id=int(cat), limit=lim)
                df_global_update(df)

                # ADDED: Handle database append if requested
                if append_db and DB_FILES:
                    for db_file in DB_FILES:
                        try:
                            conn = sqlite3.connect(db_file)
                            df.to_sql("tiki_products", conn, if_exists="append", index=False)
                            conn.commit()
                            conn.close()
                        except Exception as e:
                            log.error(f"L·ªói khi ghi v√†o CSDL {db_file}: {e}")

                progress.destroy()
                show_message(
                    f"Crawl xong: {len(df)} s·∫£n ph·∫©m. CSV & DB ƒë√£ c·∫≠p nh·∫≠t." if append_db else f"Crawl xong: {len(df)} s·∫£n ph·∫©m. CSV ƒë√£ l∆∞u.")
                cap_nhat_bang()
                cap_nhat_cot()
                hien_thi_preview(df_global)
            except Exception as e:
                progress.destroy()
                log.exception("Crawl l·ªói")
                show_error(str(e))

        threading.Thread(target=worker, daemon=True).start()

    ttk.Button(button_frame, text="üï∑Ô∏è B·∫Øt ƒë·∫ßu crawl", command=go, style="Accent.TButton").pack(side=tk.LEFT, padx=10)
    ttk.Button(button_frame, text="‚ùå H·ªßy", command=dlg.destroy).pack(side=tk.LEFT, padx=10)

# ---------------- Data management ----------------
def df_global_update(df):
    global df_global
    if df is None:
        return
    if not isinstance(df, pd.DataFrame):
        df = pd.DataFrame(df)
    if df_global is None or df_global.empty:
        df_global = df.copy()
    else:
        df_global = pd.concat([df_global, df], ignore_index=True)
        # try to coerce common columns to string for dedup
        for c in ["Link", "Ng√†y crawl", "T√™n s·∫£n ph·∫©m"]:
            if c in df_global.columns:
                df_global[c] = df_global[c].astype(str)
        df_global.drop_duplicates(subset=[c for c in ["Link", "Ng√†y crawl", "T√™n s·∫£n ph·∫©m"] if c in df_global.columns],
                                  inplace=True, ignore_index=True)

# Replace the action_import_files function with this optimized version
def action_import_files():
    files = filedialog.askopenfilenames(
        title="Ch·ªçn file d·ªØ li·ªáu",
        filetypes=[
            ("T·∫•t c·∫£ h·ªó tr·ª£", "*.csv *.xlsx *.xls *.json"),
            ("CSV", "*.csv"),
            ("Excel", "*.xlsx;*.xls"),
            ("JSON", "*.json"),
            ("All files", "*.*")
        ]
    )
    if not files:
        return

    progress = tk.Toplevel(root)
    progress.title("ƒêang x·ª≠ l√Ω")
    progress.geometry("300x120")
    progress.transient(root)
    progress.grab_set()

    tk.Label(progress, text="ƒêang import d·ªØ li·ªáu...").pack(pady=5)
    progress_bar = ttk.Progressbar(progress, orient='horizontal', length=250, mode='determinate')
    progress_bar.pack(pady=5)
    progress_bar['maximum'] = len(files)
    progress.update()

    def import_thread():
        dfs = []
        file_names = []
        success_count = 0
        fail_count = 0

        for i, f in enumerate(files):
            try:
                df = None
                if f.lower().endswith(".csv"):
                    # Try multiple encodings with UTF-8 BOM first
                    encodings = ['utf-8-sig', 'utf-8', 'latin-1', 'cp1258', 'iso-8859-1']

                    for enc in encodings:
                        try:
                            # Try to detect delimiter first
                            with open(f, 'r', encoding=enc) as test_file:
                                sample = test_file.read(4096)
                                dialect = csv.Sniffer().sniff(sample)

                            df = pd.read_csv(
                                f,
                                encoding=enc,
                                delimiter=dialect.delimiter,
                                dtype=str,
                                on_bad_lines='skip',
                                engine='python',
                                quoting=csv.QUOTE_MINIMAL,
                                escapechar='\\'
                            )
                            break
                        except (UnicodeDecodeError, csv.Error):
                            continue
                        except Exception as e:
                            log.error(f"L·ªói ƒë·ªçc CSV {f} v·ªõi encoding {enc}: {e}")
                            continue

                    if df is None:
                        # Fallback: try without delimiter detection
                        for enc in encodings:
                            try:
                                df = pd.read_csv(
                                    f,
                                    encoding=enc,
                                    dtype=str,
                                    on_bad_lines='skip',
                                    engine='python',
                                    quoting=csv.QUOTE_MINIMAL,
                                    escapechar='\\'
                                )
                                break
                            except (UnicodeDecodeError, csv.Error):
                                continue

                elif f.lower().endswith((".xlsx", ".xls")):
                    try:
                        df = pd.read_excel(f, dtype=str, engine='openpyxl')
                    except Exception as e:
                        log.error(f"L·ªói ƒë·ªçc Excel {f}: {e}")
                        # Try with different engine
                        try:
                            df = pd.read_excel(f, dtype=str, engine='xlrd')
                        except:
                            raise

                elif f.lower().endswith(".json"):
                    try:
                        df = pd.read_json(f, dtype=str, orient="records")
                    except:
                        try:
                            df = pd.read_json(f, dtype=str, lines=True)
                        except:
                            with open(f, "r", encoding="utf-8") as jf:
                                raw = json.load(jf)
                            if isinstance(raw, dict):
                                raw = [raw]
                            df = pd.json_normalize(raw)
                else:
                    raise ValueError(f"ƒê·ªãnh d·∫°ng file {f} kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.")

                if df is not None and not df.empty:
                    # Clean column names (remove BOM and extra spaces)
                    df.columns = df.columns.str.replace('\ufeff', '').str.strip()
                    df = rename_standard_columns(df)
                    dfs.append(df)
                    file_names.append(os.path.basename(f))
                    success_count += 1
                else:
                    fail_count += 1
                    log.warning(f"File {f} r·ªóng ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc")

            except Exception as e:
                fail_count += 1
                error_msg = f"L·ªói ƒë·ªçc file {f}:\n{str(e)}"
                log.error(error_msg)
                root.after(0, lambda e=error_msg: show_error(e))
                continue
            finally:
                # Update progress bar
                root.after(0, lambda i=i: progress_bar.config(value=i + 1))

        # Batch_update the file listbox after all processing is done
        if file_names:
            root.after(0, lambda: [listbox_files.insert(tk.END, name) for name in file_names])

        if dfs:
            # Use concat with ignore_index for better performance
            merged = pd.concat(dfs, ignore_index=True, sort=False)

            # Optimize numeric conversion
            numeric_columns = ['ƒê√£ b√°n', 'Gi√°', 'Gi√° g·ªëc', 'Gi·∫£m gi√° (%)']
            for col in numeric_columns:
                if col in merged.columns:
                    # Use to_numeric with errors='coerce' for better performance
                    merged[col] = pd.to_numeric(
                        merged[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True),
                        errors='coerce'
                    ).fillna(0)

            df_global_update(merged)
            root.after(0, lambda: [
                cap_nhat_cot(),
                hien_thi_preview(df_global),
                progress.destroy(),
                show_message(
                    f"ƒê√£ import {success_count} file(s) th√†nh c√¥ng, {fail_count} file(s) th·∫•t b·∫°i. D·ªØ li·ªáu s·∫µn s√†ng, ch∆∞a ghi v√†o SQLite.")
            ])
        else:
            root.after(0, lambda: [
                progress.destroy(),
                show_error("Kh√¥ng th·ªÉ ƒë·ªçc b·∫•t k·ª≥ file n√†o. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.")
            ])

    # Use a separate thread for import to prevent GUI freezing
    threading.Thread(target=import_thread, daemon=True).start()

def rename_standard_columns(df):
    mmap = {}
    # various possible names
    colmap = {
        'Ngay_crawl': 'Ng√†y crawl', 'Ngay crawl': 'Ng√†y crawl', 'NgayCrawl': 'Ng√†y crawl',
        'Ten_san_pham': 'T√™n s·∫£n ph·∫©m', 'Ten san pham': 'T√™n s·∫£n ph·∫©m', 'Ten': 'T√™n s·∫£n ph·∫©m',
        'Gia': 'Gi√°', 'gia': 'Gi√°', 'price': 'Gi√°',
        'Gia_goc': 'Gi√° g·ªëc', 'Gia goc': 'Gi√° g·ªëc', 'original_price': 'Gi√° g·ªëc',
        'Giam_gia': 'Gi·∫£m gi√° (%)', 'Giam gia': 'Gi·∫£m gi√° (%)', 'discount': 'Gi·∫£m gi√° (%)',
        'Da_ban': 'ƒê√£ b√°n', 'Da ban': 'ƒê√£ b√°n', 'DaBan': 'ƒê√£ b√°n', 'sold': 'ƒê√£ b√°n',
        'Link': 'Link', 'URL': 'Link', 'url': 'Link'
    }
    for k, v in colmap.items():
        if k in df.columns and v not in df.columns:
            mmap[k] = v
    if mmap:
        df = df.rename(columns=mmap)
    return df


# ---------------- Preview & Filter ----------------
def hien_thi_preview(df):
    """
    Hi·ªÉn th·ªã DataFrame v√†o v√πng frame_preview.
    An to√†n: d·ªçn s·∫°ch widget c≈©, x·ª≠ l√Ω df r·ªóng, t·∫°o Treeview + thanh cu·ªôn b·∫±ng pack.
    """
    try:
        # x√≥a n·ªôi dung c≈©
        for w in frame_preview.winfo_children():
            try:
                w.destroy()
            except Exception:
                pass

        if df is None or df.empty:
            lbl = tk.Label(frame_preview, text="Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã", anchor="center", bg='white')
            lbl.pack(fill=tk.BOTH, expand=True)
            return

        # Frame ch·ª©a treeview + scrollbar (d√πng pack ƒë·ªÉ tr√°nh mix grid/pack tr√™n c√πng master)
        tree_frame = tk.Frame(frame_preview, bg='white')
        tree_frame.pack(fill=tk.BOTH, expand=True)

        vsb = ttk.Scrollbar(tree_frame, orient="vertical")
        hsb = ttk.Scrollbar(tree_frame, orient="horizontal")

        cols = list(df.columns)
        tree = ttk.Treeview(tree_frame, columns=cols, show="headings", yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        vsb.config(command=tree.yview)
        hsb.config(command=tree.xview)

        # ƒë·∫∑t v·ªã tr√≠ b·∫±ng pack
        vsb.pack(side=tk.RIGHT, fill=tk.Y)
        hsb.pack(side=tk.BOTTOM, fill=tk.X)
        tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        # header & col width
        for c in cols:
            tree.heading(c, text=c)
            tree.column(c, width=140, minwidth=80, anchor="w")

        # show up to 200 rows
        maxr = min(200, len(df))
        for i in range(maxr):
            row = list(df.iloc[i].fillna("").astype(str))
            tree.insert("", tk.END, values=row)

        # auto resize columns (t∆∞∆°ng ƒë·ªëi)
        def auto_resize_columns():
            for col in cols:
                try:
                    max_len = max(df[col].astype(str).str.len().max() if not df.empty else 0, len(col))
                    tree.column(col, width=min(400, max(80, int(max_len * 7))))
                except Exception:
                    tree.column(col, width=140)

        auto_resize_columns()

        # right click menu ƒë·ªÉ xu·∫•t
        def on_rclick(event):
            sel = tree.selection()
            if not sel:
                return

            menu = tk.Menu(root, tearoff=0)

            def export_selected_csv():
                rows = [tree.item(i)["values"] for i in sel]
                cols_local = cols
                out_df = pd.DataFrame(rows, columns=cols_local)
                path = filedialog.asksaveasfilename(defaultextension=".csv", filetypes=[("CSV", "*.csv")],
                                                    title="Xu·∫•t d·ªØ li·ªáu ƒë√£ ch·ªçn")
                if path:
                    out_df.to_csv(path, index=False, encoding='utf-8-sig')
                    show_message(f"ƒê√£ xu·∫•t {len(out_df)} h√†ng ra {path}")

            menu.add_command(label="Xu·∫•t c√°c d√≤ng ƒë√£ ch·ªçn ra CSV", command=export_selected_csv)
            try:
                menu.tk_popup(event.x_root, event.y_root)
            finally:
                try:
                    menu.grab_release()
                except Exception:
                    pass

        tree.bind("<Button-3>", on_rclick)

    except Exception as e:
        log.exception("hien_thi_preview error")
        # n·∫øu l·ªói UI, hi·ªÉn th·ªã label thay v√¨ crash
        for w in frame_preview.winfo_children():
            try:
                w.destroy()
            except Exception:
                pass
        lbl = tk.Label(frame_preview, text=f"L·ªói khi hi·ªÉn th·ªã preview:\n{e}", anchor="center", bg='white', fg='red',
                       justify='center')
        lbl.pack(fill=tk.BOTH, expand=True)


def filter_preview():
    global df_global
    if df_global is None or df_global.empty:
        return

    q = entry_filter.get().strip().lower()
    if not q:
        hien_thi_preview(df_global)
        return

    df = df_global.copy()
    mask = pd.Series(False, index=df.index)
    for c in df.columns:
        try:
            mask = mask | df[c].astype(str).str.lower().str.contains(q, na=False)
        except Exception:
            continue

    res = df[mask]
    hien_thi_preview(res)


# ---------------- Export ----------------
def export_current_csv():
    global df_global
    if df_global is None or df_global.empty:
        show_error("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t.")
        return

    path = filedialog.asksaveasfilename(
        defaultextension=".csv",
        filetypes=[("CSV", "*.csv")],
        title="Xu·∫•t d·ªØ li·ªáu CSV"
    )
    if path:
        try:
            df_global.to_csv(path, index=False, encoding='utf-8-sig')
            show_message(f"ƒê√£ xu·∫•t CSV: {path}")
        except Exception as e:
            show_error(f"L·ªói khi xu·∫•t CSV: {str(e)}")


def export_current_excel():
    global df_global
    if df_global is None or df_global.empty:
        show_error("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t.")
        return

    path = filedialog.asksaveasfilename(
        defaultextension=".xlsx",
        filetypes=[("Excel", "*.xlsx")],
        title="Xu·∫•t d·ªØ li·ªáu Excel"
    )
    if path:
        try:
            df_global.to_excel(path, index=False)
            show_message(f"ƒê√£ xu·∫•t Excel: {path}")
        except Exception as e:
            show_error(f"L·ªói khi xu·∫•t Excel: {str(e)}")

def export_report_pdf():
    if not FPDF_OK:
        show_error("Th∆∞ vi·ªán fpdf ch∆∞a ƒë∆∞·ª£c c√†i. C√†i ƒë·∫∑t: pip install fpdf")
        return

    global df_global, fig_global
    if df_global is None or df_global.empty:
        show_error("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t b√°o c√°o.")
        return

    path = filedialog.asksaveasfilename(
        defaultextension=".pdf",
        filetypes=[("PDF", "*.pdf")],
        title="Xu·∫•t b√°o c√°o PDF"
    )
    if not path:
        return

    try:
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", size=12)
        pdf.cell(0, 10, APP_TITLE, ln=1, align="C")
        pdf.ln(4)
        pdf.set_font("Arial", size=10)
        pdf.cell(0, 8, f"Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", ln=1)
        pdf.cell(0, 8, f"S·ªë d√≤ng d·ªØ li·ªáu hi·ªán t·∫°i: {len(df_global)}", ln=1)
        pdf.ln(4)
        pdf.cell(0, 8, "Top 10 s·∫£n ph·∫©m theo 'ƒê√£ b√°n' (n·∫øu c√≥):", ln=1)

        try:
            if 'ƒê√£ b√°n' in df_global.columns:
                top = df_global.sort_values("ƒê√£ b√°n", ascending=False).head(10)
                pdf.set_font("Arial", size=9)
                for idx, row in top.iterrows():
                    name = str(row.get('T√™n s·∫£n ph·∫©m', ''))[:40]
                    sold = str(row.get('ƒê√£ b√°n', ''))
                    price = str(row.get('Gi√°', ''))
                    line = f"{name:40} | ƒê√£ b√°n: {sold} | Gi√°: {price}"
                    pdf.multi_cell(0, 6, line)
            else:
                pdf.multi_cell(0, 6, "Kh√¥ng c√≥ d·ªØ li·ªáu 'ƒê√£ b√°n'.")
        except Exception:
            pdf.multi_cell(0, 6, "L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu 'ƒê√£ b√°n'.")

        pdf.output(path)
        show_message(f"ƒê√£ xu·∫•t b√°o c√°o PDF: {path}")
    except Exception as e:
        show_error(f"L·ªói khi xu·∫•t PDF: {str(e)}")

# ---------------- SQL & Chart ----------------
def cap_nhat_bang():
    global DB_FILES
    all_tables = []

    for db_file in DB_FILES:
        if os.path.exists(db_file):
            try:
                conn = sqlite3.connect(db_file)
                cur = conn.cursor()
                cur.execute("SELECT name FROM sqlite_master WHERE type='table';")
                tables = [f"{os.path.basename(db_file)}::{t[0]}" for t in cur.fetchall()]
                all_tables.extend(tables)
                conn.close()
            except Exception as e:
                log.exception(f"Error reading tables from {db_file}")
                continue

    combo_table['values'] = all_tables
    if all_tables:
        combo_table.set(all_tables[0])


def cap_nhat_cot_from_table(tab=None):
    cols = []
    if tab and "::" in tab:
        db_name, table_name = tab.split("::", 1)
        db_path = None
        for db_file in DB_FILES:
            if os.path.basename(db_file) == db_name:
                db_path = db_file
                break

        if db_path:
            try:
                conn = sqlite3.connect(db_path)
                df = pd.read_sql_query(f'SELECT * FROM "{table_name}" LIMIT 1', conn)
                cols = list(df.columns)
                conn.close()
            except Exception:
                cols = []
    else:
        if df_global is not None and not df_global.empty:
            cols = list(df_global.columns)

    combo_x['values'] = cols
    combo_y['values'] = cols
    if cols:
        combo_x.set(cols[0])
        if len(cols) > 1:
            combo_y.set(cols[1])

def cap_nhat_cot():
    if df_global is not None and not df_global.empty:
        cols = list(df_global.columns)
        combo_x['values'] = cols
        combo_y['values'] = cols
        if cols:
            combo_x.set(cols[0])
            if len(cols) > 1:
                combo_y.set(cols[1])

def chay_sql_va_ve():
    global df_global, DB_FILES, fig_global
    sql = text_sql.get("1.0", tk.END).strip()
    chart_type = combo_chart.get()
    x_col = combo_x.get()
    y_col = combo_y.get()
    table_name_raw = combo_table.get().strip() if combo_table.get() else ""

    # ƒë·∫£m b·∫£o c√≥ DB file (t·∫°o m·∫∑c ƒë·ªãnh n·∫øu ch∆∞a)
    ensure_db_files()

    if not DB_FILES:
        show_error("Ch∆∞a ch·ªçn CSDL n√†o.")
        return

    all_dfs = []  # L∆∞u tr·ªØ k·∫øt qu·∫£ t·ª´ t·∫•t c·∫£ c√°c CSDL

    # X·ª≠ l√Ω t√™n b·∫£ng n·∫øu c√≥ format dbname::tablename
    table_name = ""
    if table_name_raw and "::" in table_name_raw:
        db_name, table_name = table_name_raw.split("::", 1)
    elif table_name_raw:
        # sanitize: ch·ªâ c√≤n a-z0-9_
        table_name = re.sub(r'[^0-9a-zA-Z_]', '_', table_name_raw)
        if re.match(r'^\d', table_name):
            table_name = 't_' + table_name
        table_name = table_name.lower()

    # N·∫øu user nh·∫≠p t√™n b·∫£ng m·ªõi: t·∫°o t·ª´ df_global trong t·∫•t c·∫£ CSDL
    if table_name and not table_name_raw.startswith("::"):
        if df_global is None or df_global.empty:
            show_error("Ch∆∞a c√≥ d·ªØ li·ªáu trong b·ªô nh·ªõ ƒë·ªÉ t·∫°o b·∫£ng m·ªõi.")
            return

        for db_file in DB_FILES:
            try:
                conn = sqlite3.connect(db_file)
                df_global.to_sql(table_name, conn, if_exists="replace", index=False)
                conn.commit()
                conn.close()
            except Exception as e:
                log.exception(f"L·ªói khi t·∫°o b·∫£ng m·ªõi trong {db_file}")
                show_error(f"L·ªói khi t·∫°o b·∫£ng '{table_name}' trong {db_file}: {e}")
                return

    for db_file in DB_FILES:
        conn = None
        try:
            conn = sqlite3.connect(db_file)
            cur = conn.cursor()

            # N·∫øu c√≥ SQL th√¨ ch·∫°y tr·ª±c ti·∫øp
            if sql:
                try:
                    df = pd.read_sql_query(sql, conn)
                except Exception as e:
                    log.exception("L·ªói khi ch·∫°y SQL")
                    show_error(f"L·ªói khi ch·∫°y SQL tr√™n {db_file}: {e}")
                    continue
            else:
                if not (table_name and x_col and y_col):
                    show_error("Ch∆∞a ch·ªçn b·∫£ng v√†/ho·∫∑c c·ªôt X/Y.")
                    return

                # ki·ªÉm tra b·∫£ng t·ªìn t·∫°i
                cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
                if not cur.fetchone():
                    show_error(f"B·∫£ng '{table_name}' kh√¥ng t·ªìn t·∫°i trong CSDL {db_file}.")
                    continue

                try:
                    # D√πng alias X, Y ƒë·ªÉ ƒë·ªìng nh·∫•t
                    df = pd.read_sql_query(
                        f'SELECT "{x_col}" as X, "{y_col}" as Y FROM "{table_name}"', conn
                    )
                except Exception as e:
                    log.exception("L·ªói khi ƒë·ªçc b·∫£ng")
                    show_error(f"L·ªói khi ƒë·ªçc b·∫£ng '{table_name}' t·ª´ {db_file}: {e}")
                    continue

            if df is None or df.empty:
                show_error(f"K·∫øt qu·∫£ r·ªóng t·ª´ {db_file}. Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω.")
                continue

            df['source_db'] = os.path.basename(db_file)
            all_dfs.append(df)

        except Exception as e:
            log.exception(f"L·ªói khi x·ª≠ l√Ω CSDL {db_file}")
            show_error(f"L·ªói khi x·ª≠ l√Ω CSDL {db_file}: {e}")
        finally:
            if conn:
                try:
                    conn.close()
                except Exception:
                    pass

    if not all_dfs:
        show_error("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
        return

    combined_df = pd.concat(all_dfs, ignore_index=True)

    # X√≥a bi·ªÉu ƒë·ªì c≈©
    for widget in frame_chart.winfo_children():
        widget.destroy()

    fig, ax = plt.subplots(figsize=(10, 6))

    try:
        # V·∫Ω d·ª±a tr√™n alias X, Y
        if chart_type == 'Bar':
            ax.bar(combined_df["X"], combined_df["Y"])
        elif chart_type == 'Line':
            ax.plot(combined_df["X"], combined_df["Y"])
        elif chart_type == 'Pie':
            ax.pie(combined_df["Y"], labels=combined_df["X"], autopct='%1.1f%%')
        elif chart_type == 'Scatter':
            ax.scatter(combined_df["X"], combined_df["Y"])

        ax.set_title(f'Bi·ªÉu ƒë·ªì {chart_type}')
        ax.set_xlabel(x_col)  # Hi·ªÉn th·ªã label g·ªëc
        ax.set_ylabel(y_col)
        plt.xticks(rotation=45)
        plt.tight_layout()

        canvas = FigureCanvasTkAgg(fig, master=frame_chart)
        canvas.draw()
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

        fig_global = fig
        frame_chart.canvas_fig = fig

    except Exception as e:
        show_error(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {str(e)}")


def add_db_files():
    files = filedialog.askopenfilenames(
        title="Ch·ªçn file SQLite",
        filetypes=[("SQLite files", "*.db"), ("All files", "*.*")]
    )
    if files:
        for file_path in files:
            # Chu·∫©n h√≥a ƒë∆∞·ªùng d·∫´n
            file_path = os.path.normpath(file_path)
            if file_path not in DB_FILES:
                DB_FILES.append(file_path)
                listbox_dbs.insert(tk.END, file_path)


def remove_db_file():
    selected = listbox_dbs.curselection()
    if selected:
        index = selected[0]
        DB_FILES.pop(index)
        listbox_dbs.delete(index)
        cap_nhat_bang()  # C·∫≠p nh·∫≠t danh s√°ch b·∫£ng sau khi x√≥a CSDL


def phong_to():
    if hasattr(frame_chart, "canvas_fig"):
        fig = frame_chart.canvas_fig
        win = tk.Toplevel(root)
        win.title("Ph√≥ng to bi·ªÉu ƒë·ªì")
        win.geometry("1000x700")

        canvas = FigureCanvasTkAgg(fig, master=win)
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        canvas.draw()

        # N√∫t ƒë√≥ng
        ttk.Button(win, text="‚ùå ƒê√≥ng", command=win.destroy, style="Accent.TButton").pack(pady=5)
    else:
        show_error("Ch∆∞a c√≥ bi·ªÉu ƒë·ªì ƒë·ªÉ ph√≥ng to.")

def save_chart_image():
    global fig_global
    if not fig_global:
        show_error("Ch∆∞a c√≥ bi·ªÉu ƒë·ªì ƒë·ªÉ l∆∞u.")
        return

    path = filedialog.asksaveasfilename(
        defaultextension=".png",
        filetypes=[("PNG", "*.png"), ("JPEG", "*.jpg"), ("PDF", "*.pdf")],
        title="L∆∞u bi·ªÉu ƒë·ªì"
    )
    if path:
        try:
            fig_global.savefig(path, bbox_inches='tight', dpi=300)
            show_message(f"ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {path}")
        except Exception as e:
            show_error(f"L·ªói khi l∆∞u bi·ªÉu ƒë·ªì: {str(e)}")


# Th√™m h√†m t√¨m ki·∫øm s·∫£n ph·∫©m trong tab SQL
def search_product_sql():
    global df_global
    search_term = entry_search_sql.get().strip().lower()
    if not search_term:
        # N·∫øu kh√¥ng c√≥ t·ª´ kh√≥a t√¨m ki·∫øm, hi·ªÉn th·ªã l·∫°i d·ªØ li·ªáu g·ªëc
        hien_thi_preview(df_global)
        return

    # Ki·ªÉm tra xem c√≥ b·∫£ng n√†o ƒë∆∞·ª£c ch·ªçn t·ª´ combobox kh√¥ng
    selected_table = combo_table.get().strip()
    if selected_table and "::" in selected_table:
        # N·∫øu c√≥ b·∫£ng ƒë∆∞·ª£c ch·ªçn, t√¨m ki·∫øm trong database
        db_name, table_name = selected_table.split("::", 1)
        db_path = None
        for db_file in DB_FILES:
            if os.path.basename(db_file) == db_name:
                db_path = db_file
                break

        if db_path:
            try:
                conn = sqlite3.connect(db_path)
                # ƒê·ªçc to√†n b·ªô d·ªØ li·ªáu t·ª´ b·∫£ng
                df_db = pd.read_sql_query(f'SELECT * FROM "{table_name}"', conn)
                conn.close()

                # T√¨m c·ªôt ch·ª©a t√™n s·∫£n ph·∫©m
                product_columns = ['T√™n s·∫£n ph·∫©m', 'ten_san_pham', 'product_name', 'name', 'title']
                product_col = None
                for col in product_columns:
                    if col in df_db.columns:
                        product_col = col
                        break

                if product_col:
                    # L·ªçc d·ªØ li·ªáu t·ª´ database
                    filtered_df = df_db[df_db[product_col].astype(str).str.lower().str.contains(search_term, na=False)]
                    hien_thi_preview(filtered_df)
                else:
                    show_error("Kh√¥ng t√¨m th·∫•y c·ªôt t√™n s·∫£n ph·∫©m trong b·∫£ng database.")
            except Exception as e:
                show_error(f"L·ªói khi ƒë·ªçc t·ª´ database: {str(e)}")
        else:
            show_error("Kh√¥ng t√¨m th·∫•y database ph√π h·ª£p.")
    else:
        # N·∫øu kh√¥ng c√≥ b·∫£ng ƒë∆∞·ª£c ch·ªçn, t√¨m trong df_global (d·ªØ li·ªáu t·ª´ file)
        if df_global is None or df_global.empty:
            show_error("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ t√¨m ki·∫øm.")
            return

        # T√¨m c·ªôt ch·ª©a t√™n s·∫£n ph·∫©m
        product_columns = ['T√™n s·∫£n ph·∫©m', 'ten_san_pham', 'product_name', 'name', 'title']
        product_col = None
        for col in product_columns:
            if col in df_global.columns:
                product_col = col
                break

        if not product_col:
            show_error("Kh√¥ng t√¨m th·∫•y c·ªôt t√™n s·∫£n ph·∫©m trong d·ªØ li·ªáu.")
            return

        # L·ªçc d·ªØ li·ªáu
        filtered_df = df_global[df_global[product_col].astype(str).str.lower().str.contains(search_term, na=False)]
        hien_thi_preview(filtered_df)

# ---------------- ML features ----------------
def prepare_processed_from_df_global():
    global processed_df, df_global

    # Ki·ªÉm tra xem c√≥ b·∫£ng n√†o ƒë∆∞·ª£c ch·ªçn kh√¥ng
    selected_table = combo_table.get().strip()
    if not selected_table or "::" not in selected_table:
        show_error("Vui l√≤ng ch·ªçn m·ªôt b·∫£ng d·ªØ li·ªáu t·ª´ tab SQL & Tr·ª±c quan tr∆∞·ªõc khi chu·∫©n h√≥a.")
        return

    # L·∫•y th√¥ng tin database v√† b·∫£ng t·ª´ combobox
    db_name, table_name = selected_table.split("::", 1)

    # T√¨m ƒë∆∞·ªùng d·∫´n database
    db_path = None
    for db_file in DB_FILES:
        if os.path.basename(db_file) == db_name:
            db_path = db_file
            break

    if not db_path:
        show_error(f"Kh√¥ng t√¨m th·∫•y database: {db_name}")
        return

    try:
        # ƒê·ªçc d·ªØ li·ªáu t·ª´ b·∫£ng ƒë√£ ch·ªçn
        conn = sqlite3.connect(db_path)
        df = pd.read_sql_query(f'SELECT * FROM "{table_name}"', conn)
        conn.close()
    except Exception as e:
        show_error(f"L·ªói khi ƒë·ªçc b·∫£ng {table_name}: {str(e)}")
        return

    # Ti·∫øp t·ª•c x·ª≠ l√Ω d·ªØ li·ªáu nh∆∞ tr∆∞·ªõc
    df = rename_standard_columns(df)

    # ensure date col
    if "Ng√†y crawl" in df.columns:
        df['Ng√†y crawl'] = pd.to_datetime(df['Ng√†y crawl'], errors='coerce')
    elif 'Ngay_crawl' in df.columns:
        df['Ng√†y crawl'] = pd.to_datetime(df['Ngay_crawl'], errors='coerce')
    else:
        df['Ng√†y crawl'] = datetime.now()

    for c in ['ƒê√£ b√°n', 'Gi√°']:
        if c in df.columns:
            df[c] = pd.to_numeric(
                df[c].astype(str).str.replace(r'[^0-9.-]', '', regex=True),
                errors='coerce'
            ).fillna(0)

    df['Th√°ng'] = df['Ng√†y crawl'].dt.strftime('%Y-%m')
    df['SanPhamID'] = df['Link'].apply(lambda x: extract_id(x) if pd.notna(x) else None)

    agg = df.groupby(['SanPhamID', 'T√™n s·∫£n ph·∫©m', 'Th√°ng'], dropna=False).agg({
        'ƒê√£ b√°n': 'max',
        'Gi√°': 'mean'
    }).reset_index()

    agg['DoanhSoTh√°ng'] = agg.groupby('SanPhamID')['ƒê√£ b√°n'].diff().fillna(agg['ƒê√£ b√°n'])

    # Normalize column names
    agg.rename(columns={
        'T√™n s·∫£n ph·∫©m': 'ten_san_pham',
        'Th√°ng': 'thang',
        'DoanhSoTh√°ng': 'doanhso_thang',
        'SanPhamID': 'sanpham_id'
    }, inplace=True)

    processed_df = agg

    # update listbox products
    listbox_products.delete(0, tk.END)
    for p in processed_df['ten_san_pham'].unique():
        if pd.notna(p):
            listbox_products.insert(tk.END, p)
    show_message('ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu t·ª´ b·∫£ng ƒë√£ ch·ªçn cho tab H·ªçc m√°y.')


def load_ml_data_from_db():
    global processed_df, DB_FILES

    if not DB_FILES:
        show_error("Ch∆∞a ch·ªçn file database n√†o.")
        return

    all_data = []
    for db_file in DB_FILES:
        try:
            conn = sqlite3.connect(db_file)
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = [table[0] for table in cursor.fetchall()]
            for table in tables:
                try:
                    df = pd.read_sql_query(f"SELECT * FROM {table}", conn)
                    # Chu·∫©n h√≥a t√™n c·ªôt
                    df.columns = [col.lower().replace(" ", "_") for col in df.columns]
                    all_data.append(df)
                except Exception as e:
                    print(f"L·ªói khi ƒë·ªçc b·∫£ng {table}: {e}")
            conn.close()
        except Exception as e:
            print(f"L·ªói k·∫øt n·ªëi database {db_file}: {e}")
            continue

    if not all_data:
        show_error("Kh√¥ng c√≥ d·ªØ li·ªáu trong database.")
        return

    # G·ªôp d·ªØ li·ªáu v√† x·ª≠ l√Ω
    df = pd.concat(all_data, ignore_index=True)
    # Ch·ªâ gi·ªØ c√°c c·ªôt c·∫ßn thi·∫øt, ƒë·ªïi t√™n cho ƒë·ªìng nh·∫•t
    col_map = {
        "ten_san_pham": "T√™n s·∫£n ph·∫©m",
        "da_ban": "ƒê√£ b√°n",
        "ngay_crawl": "Ng√†y crawl",
        "gia": "Gi√°",
        "link": "Link"
    }
    for k, v in col_map.items():
        if k in df.columns:
            df.rename(columns={k: v}, inplace=True)
    # Lo·∫°i b·ªè c√°c d√≤ng thi·∫øu d·ªØ li·ªáu quan tr·ªçng
    df = df.dropna(subset=["T√™n s·∫£n ph·∫©m", "ƒê√£ b√°n", "Ng√†y crawl"])
    # Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu
    df["ƒê√£ b√°n"] = pd.to_numeric(df["ƒê√£ b√°n"], errors="coerce").fillna(0)
    df["Ng√†y crawl"] = pd.to_datetime(df["Ng√†y crawl"], errors="coerce")
    df = df[df["Ng√†y crawl"].notna()]
    # T√≠nh th√°ng
    df["Th√°ng"] = df["Ng√†y crawl"].dt.strftime("%Y-%m")
    # G·ªôp theo s·∫£n ph·∫©m v√† th√°ng
    agg = df.groupby(["T√™n s·∫£n ph·∫©m", "Th√°ng"]).agg({"ƒê√£ b√°n": "max"}).reset_index()
    agg["Doanh s·ªë th√°ng"] = agg.groupby("T√™n s·∫£n ph·∫©m")["ƒê√£ b√°n"].diff().fillna(agg["ƒê√£ b√°n"])

    # Normalize column names
    agg.rename(columns={
        'T√™n s·∫£n ph·∫©m': 'ten_san_pham',
        'Th√°ng': 'thang',
        'Doanh s·ªë th√°ng': 'doanhso_thang'
    }, inplace=True)

    processed_df = agg

    # C·∫≠p nh·∫≠t listbox s·∫£n ph·∫©m
    listbox_products.delete(0, tk.END)
    for sp in processed_df["ten_san_pham"].unique():
        listbox_products.insert(tk.END, sp)
    show_message(f"ƒê√£ t·∫£i {len(processed_df)} b·∫£n ghi t·ª´ database.")


def process_data():
    try:
        df = df_global.copy()
        df = rename_standard_columns(df)

        # ensure date col
        if "Ng√†y crawl" in df.columns:
            df['Ng√†y crawl'] = pd.to_datetime(df['Ng√†y crawl'], errors='coerce')
        elif 'Ngay_crawl' in df.columns:
            df['Ng√†y crawl'] = pd.to_datetime(df['Ngay_crawl'], errors='coerce')
        else:
            # N·∫øu kh√¥ng c√≥ c·ªôt ng√†y, th√™m c·ªôt v·ªõi ng√†y hi·ªán t·∫°i
            df['Ng√†y crawl'] = datetime.now()

        # coerce numeric
        for c in ['ƒê√£ b√°n', 'Gi√°']:
            if c in df.columns:
                df[c] = pd.to_numeric(
                    df[c].astype(str).str.replace(r'[^0-9.-]', '', regex=True),
                    errors='coerce'
                ).fillna(0)

        df['Th√°ng'] = df['Ng√†y crawl'].dt.strftime('%Y-%m')
        df['SanPhamID'] = df['Link'].apply(lambda x: extract_id(x) if pd.notna(x) else None)

        agg = df.groupby(['SanPhamID', 'T√™n s·∫£n ph·∫©m', 'Th√°ng'], dropna=False).agg({
            'ƒê√£ b√°n': 'max',
            'Gi√°': 'mean'
        }).reset_index()

        agg['DoanhSoTh√°ng'] = agg.groupby('SanPhamID')['ƒê√£ b√°n'].diff().fillna(agg['ƒê√£ b√°n'])

        # Normalize column names
        agg.rename(columns={
            'T√™n s·∫£n ph·∫©m': 'ten_san_pham',
            'Th√°ng': 'thang',
            'DoanhSoTh√°ng': 'doanhso_thang',
            'SanPhamID': 'sanpham_id'
        }, inplace=True)

        processed_df = agg

        # update listbox products
        root.after(0, lambda: [
            listbox_products.delete(0, tk.END),
            [listbox_products.insert(tk.END, p) for p in processed_df['ten_san_pham'].unique() if pd.notna(p)],
            show_message('ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu cho tab H·ªçc m√°y.')
        ])

    except Exception as e:
        root.after(0, lambda: [
            show_error(f"L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {str(e)}")
        ])

    threading.Thread(target=process_data, daemon=True).start()


def predict_model():
    global processed_df
    if processed_df is None or processed_df.empty:
        show_error("Ch∆∞a c√≥ d·ªØ li·ªáu x·ª≠ l√Ω. Nh·∫•n 'Chu·∫©n h√≥a d·ªØ li·ªáu' tr∆∞·ªõc.")
        return

    sel = listbox_products.curselection()
    if not sel:
        show_error("Ch·ªçn 1 s·∫£n ph·∫©m ƒë·ªÉ d·ª± ƒëo√°n.")
        return

    product = listbox_products.get(sel[0])
    df = processed_df[processed_df['ten_san_pham'] == product].sort_values('thang')

    if df.empty or len(df) < 2:
        show_error("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n (√≠t nh·∫•t 2 th√°ng).")
        return

    method = combo_ml_method.get()

    if method == 'Linear Regression':
        if not SKLEARN_OK:
            show_error('scikit-learn ch∆∞a c√†i. C√†i ƒë·∫∑t: pip install scikit-learn')
            return

        X = np.arange(len(df)).reshape(-1, 1)
        y = df['doanhso_thang'].values
        model = LinearRegression()
        model.fit(X, y)
        pred = model.predict([[len(df)]])[0]
        score = model.score(X, y)

    elif method == 'Moving Average':
        try:
            window = int(entry_ma_window.get() or 3)
        except Exception:
            window = 3

        y = df['doanhso_thang'].values
        if len(y) >= window:
            pred = float(pd.Series(y).rolling(window=window).mean().iloc[-1])
        else:
            pred = float(y.mean() if len(y) > 0 else 0)
        score = float('nan')

    else:
        show_error('Ch·ªçn ph∆∞∆°ng ph√°p d·ª± ƒëo√°n.')
        return

    last = df['doanhso_thang'].iloc[-1]
    change = (pred - last) / last * 100 if last != 0 else float('inf')

    text_result.delete('1.0', tk.END)
    result_text = f"S·∫£n ph·∫©m: {product}\nPh∆∞∆°ng ph√°p: {method}\nD·ª± ƒëo√°n th√°ng k·∫ø: {pred:.2f}\nTh√°ng tr∆∞·ªõc: {last}\n"

    if pd.notna(change) and change != float('inf'):
        result_text += f"Thay ƒë·ªïi: {change:.2f}%\n"
    else:
        result_text += "Thay ƒë·ªïi: kh√¥ng x√°c ƒë·ªãnh\n"

    result_text += f"M√¥ h√¨nh R¬≤: {score:.4f}" if not pd.isna(score) else "M√¥ h√¨nh R¬≤: n/a"

    text_result.insert(tk.END, result_text)

    # X√≥a bi·ªÉu ƒë·ªì c≈©
    for w in frame_chart_ml.winfo_children():
        w.destroy()

    # T·∫°o bi·ªÉu ƒë·ªì m·ªõi
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.plot(df['thang'], df['doanhso_thang'], marker='o', label='Th·ª±c t·∫ø')
    ax.plot([df['thang'].iloc[-1], f"{df['thang'].iloc[-1]}+1"], [last, pred], 'r--o', label='D·ª± ƒëo√°n')
    ax.set_title(product)
    ax.set_xlabel('Th√°ng')
    ax.set_ylabel('Doanh s·ªë th√°ng')
    ax.legend()
    plt.xticks(rotation=45)

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trong GUI
    canvas = FigureCanvasTkAgg(fig, master=frame_chart_ml)
    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    canvas.draw()

    # L∆∞u tr·ªØ tham chi·∫øu
    frame_chart_ml.canvas_fig = fig
    frame_chart_ml.canvas_obj = canvas


# ---------------- Extra analysis ----------------
def _show_figure_in_toplevel(fig, title='Figure', size=(800, 600)):
    win = tk.Toplevel(root)
    win.title(title)
    win.geometry(f"{size[0]}x{size[1]}")

    canvas = FigureCanvasTkAgg(fig, master=win)
    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    canvas.draw()

    # N√∫t ƒë√≥ng
    ttk.Button(win, text="‚ùå ƒê√≥ng", command=win.destroy, style="Accent.TButton").pack(pady=5)


def analyze_top_products():
    global df_global
    if df_global is None or df_global.empty:
        show_error('Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch.')
        return

    df = df_global.copy()
    if 'ƒê√£ b√°n' not in df.columns:
        show_error("Kh√¥ng c√≥ c·ªôt 'ƒê√£ b√°n' trong d·ªØ li·ªáu.")
        return

    df['ƒê√£ b√°n'] = pd.to_numeric(
        df['ƒê√£ b√°n'].astype(str).str.replace(r'[^0-9.-]', '', regex=True),
        errors='coerce'
    ).fillna(0)

    top = df.groupby('T√™n s·∫£n ph·∫©m', dropna=False)['ƒê√£ b√°n'].sum().sort_values(ascending=False).head(10)

    fig, ax = plt.subplots(figsize=(8, 5))
    ax.barh(top.index.astype(str), top.values)
    ax.invert_yaxis()
    ax.set_xlabel('T·ªïng ƒë√£ b√°n')
    ax.set_title('Top 10 s·∫£n ph·∫©m b√°n ch·∫°y nh·∫•t')

    # Th√™m gi√° tr·ªã tr√™n m·ªói c·ªôt
    for i, v in enumerate(top.values):
        ax.text(v + max(top.values) * 0.01, i, str(int(v)), ha='left', va='center')

    plt.tight_layout()
    _show_figure_in_toplevel(fig, title='Top 10 s·∫£n ph·∫©m', size=(900, 600))


def compare_by_date():
    global df_global
    if df_global is None or df_global.empty:
        show_error('Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ so s√°nh.')
        return

    if 'Ng√†y crawl' not in df_global.columns:
        show_error('Kh√¥ng c√≥ c·ªôt "Ng√†y crawl" trong d·ªØ li·ªáu.')
        return

    unique_dates = sorted(df_global['Ng√†y crawl'].astype(str).unique())
    if len(unique_dates) < 2:
        show_error('C·∫ßn √≠t nh·∫•t 2 ng√†y crawl ƒë·ªÉ so s√°nh.')
        return

    # T·∫°o dialog ƒë·ªÉ ch·ªçn ng√†y
    dlg = tk.Toplevel(root)
    dlg.title("Ch·ªçn ng√†y ƒë·ªÉ so s√°nh")
    dlg.geometry("400x300")
    dlg.resizable(False, False)
    dlg.transient(root)
    dlg.grab_set()

    # Center the dialog
    dlg.update_idletasks()
    x = root.winfo_x() + (root.winfo_width() - dlg.winfo_width()) // 2
    y = root.winfo_y() + (root.winfo_height() - dlg.winfo_height()) // 2
    dlg.geometry(f"+{x}+{y}")

    tk.Label(dlg, text="Ch·ªçn ng√†y th·ª© nh·∫•t:").pack(pady=5)
    date1_var = tk.StringVar(value=unique_dates[-1] if unique_dates else "")
    date1_combo = ttk.Combobox(dlg, textvariable=date1_var, values=unique_dates, state="readonly")
    date1_combo.pack(pady=5)

    tk.Label(dlg, text="Ch·ªçn ng√†y th·ª© hai:").pack(pady=5)
    date2_var = tk.StringVar(value=unique_dates[-2] if len(unique_dates) > 1 else "")
    date2_combo = ttk.Combobox(dlg, textvariable=date2_var, values=unique_dates, state="readonly")
    date2_combo.pack(pady=5)

    def do_compare():
        d1 = date1_var.get()
        d2 = date2_var.get()
        dlg.destroy()

        if not d1 or not d2:
            show_error('Vui l√≤ng ch·ªçn c·∫£ hai ng√†y.')
            return

        # S·ª≠a l·ªói ch√≠nh t·∫£: astize -> astype
        df1 = df_global[df_global['Ng√†y crawl'].astype(str).str.contains(d1)]
        df2 = df_global[df_global['Ng√†y crawl'].astype(str).str.contains(d2)]

        if df1.empty or df2.empty:
            show_error('Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu cho m·ªôt trong hai ng√†y.')
            return

        agg1 = df1.groupby('T√™n s·∫£n ph·∫©m')['ƒê√£ b√°n'].sum().sort_values(ascending=False).head(10)
        agg2 = df2.groupby('T√™n s·∫£n ph·∫©m')['ƒê√£ b√°n'].sum().sort_values(ascending=False).head(10)

        names = list(set(agg1.index).union(set(agg2.index)))
        y1 = [agg1.get(n, 0) for n in names]
        y2 = [agg2.get(n, 0) for n in names]

        x = range(len(names))
        fig, ax = plt.subplots(figsize=(10, 6))
        w = 0.35
        ax.bar([i - w / 2 for i in x], y1, width=w, label=f"{d1}")
        ax.bar([i + w / 2 for i in x], y2, width=w, label=f"{d2}")

        ax.set_xticks(x)
        ax.set_xticklabels(names, rotation=45, ha='right')
        ax.set_ylabel('ƒê√£ b√°n')
        ax.set_title(f'So s√°nh {d1} vs {d2}')
        ax.legend()

        plt.tight_layout()
        _show_figure_in_toplevel(fig, title=f'So s√°nh {d1} vs {d2}', size=(1000, 600))

    ttk.Button(dlg, text="üìä So s√°nh", command=do_compare, style="Accent.TButton").pack(pady=20)
    ttk.Button(dlg, text="‚ùå H·ªßy", command=dlg.destroy).pack(pady=5)


# ---------------- New ML functions ----------------
def search_product_ml(*args):
    global processed_df
    if processed_df is None:
        return
    query = entry_search_ml.get().lower()
    listbox_products.delete(0, tk.END)

    # Use the correct column name based on how data was processed
    product_col = "ten_san_pham" if "ten_san_pham" in processed_df.columns else "T√™n s·∫£n ph·∫©m"

    for sp in processed_df[product_col].unique():
        if query in str(sp).lower():
            listbox_products.insert(tk.END, sp)

def predict_next_month():
    global processed_df
    if processed_df is None or processed_df.empty:
        show_error("Ch∆∞a c√≥ d·ªØ li·ªáu x·ª≠ l√Ω. Nh·∫•n 'Chu·∫©n h√≥a d·ªØ li·ªáu' tr∆∞·ªõc.")
        return

    sel = listbox_products.curselection()
    if not sel:
        show_error("Ch·ªçn 1 s·∫£n ph·∫©m ƒë·ªÉ d·ª± ƒëo√°n.")
        return

    # Validate month input
    month_input = entry_predict_month.get().strip()
    if not month_input or not re.match(r'^\d{2}/\d{4}$', month_input):
        show_error("Vui l√≤ng nh·∫≠p th√°ng d·ª± ƒëo√°n theo ƒë·ªãnh d·∫°ng MM/YYYY (v√≠ d·ª•: 12/2023)")
        return

    try:
        input_month, input_year = map(int, month_input.split('/'))
        if input_month < 1 or input_month > 12:
            show_error("Th√°ng ph·∫£i n·∫±m trong kho·∫£ng t·ª´ 01 ƒë·∫øn 12")
            return
    except ValueError:
        show_error("ƒê·ªãnh d·∫°ng th√°ng kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p theo ƒë·ªãnh d·∫°ng MM/YYYY")
        return

    # Disable predict button during processing
    btn_predict.config(state=tk.DISABLED)

    # Show progress window
    progress = tk.Toplevel(root)
    progress.title("ƒêang x·ª≠ l√Ω")
    progress.geometry("300x100")
    progress.transient(root)
    progress.grab_set()

    # Center the progress dialog
    progress.update_idletasks()
    x = root.winfo_x() + (root.winfo_width() - progress.winfo_width()) // 2
    y = root.winfo_y() + (root.winfo_height() - progress.winfo_height()) // 2
    progress.geometry(f"+{x}+{y}")

    tk.Label(progress, text="ƒêang x·ª≠ l√Ω d·ª± ƒëo√°n...").pack(pady=20)
    progress.update()

    def prediction_worker():
        try:
            product = listbox_products.get(sel[0])
            df = processed_df[processed_df['ten_san_pham'] == product].sort_values('thang')

            if df.empty or len(df) < 2:
                root.after(0, lambda: show_error("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n (√≠t nh·∫•t 2 th√°ng)."))
                return

            method = combo_ml_method.get()

            if method == 'Linear Regression':
                if not SKLEARN_OK:
                    root.after(0, lambda: show_error('scikit-learn ch∆∞a c√†i. C√†i ƒë·∫∑t: pip install scikit-learn'))
                    return

                # Convert thang to datetime and calculate months since start
                df['thang_dt'] = pd.to_datetime(df['thang'])
                start_date = df['thang_dt'].min()

                # Calculate months since start for each data point
                df['months_since_start'] = ((df['thang_dt'].dt.year - start_date.year) * 12 +
                                            (df['thang_dt'].dt.month - start_date.month))

                # Calculate months since start for prediction point
                target_date = datetime(input_year, input_month, 1)
                months_to_predict = ((target_date.year - start_date.year) * 12 +
                                     (target_date.month - start_date.month))

                # Prepare features for prediction
                X = df['months_since_start'].values.reshape(-1, 1)
                y = df['doanhso_thang'].values

                model = LinearRegression()
                model.fit(X, y)

                # Predict for the specified month and year
                pred = model.predict([[months_to_predict]])[0]
                score = model.score(X, y)

            elif method == 'Moving Average':
                try:
                    window = int(entry_ma_window.get() or 3)
                except Exception:
                    window = 3

                # Use all available data for moving average
                y = df['doanhso_thang'].values
                if len(y) >= window:
                    pred = float(pd.Series(y).rolling(window=window).mean().iloc[-1])
                else:
                    pred = float(y.mean() if len(y) > 0 else 0)
                score = float('nan')

            else:
                root.after(0, lambda: show_error('Ch·ªçn ph∆∞∆°ng ph√°p d·ª± ƒëo√°n.'))
                return

            # Get the last actual value for comparison
            last = df['doanhso_thang'].iloc[-1]
            change = (pred - last) / last * 100 if last != 0 else float('inf')

            result_text = f"S·∫£n ph·∫©m: {product}\n"
            result_text += f"Ph∆∞∆°ng ph√°p: {method}\n"
            result_text += f"Th√°ng d·ª± ƒëo√°n: {month_input}\n"
            result_text += f"D·ª± ƒëo√°n: {pred:.2f}\n"
            result_text += f"Th√°ng tr∆∞·ªõc: {last}\n"

            if pd.notna(change) and change != float('inf'):
                result_text += f"Thay ƒë·ªïi: {change:+.2f}%\n"
            else:
                result_text += "Thay ƒë·ªïi: kh√¥ng x√°c ƒë·ªãnh\n"

            result_text += f"M√¥ h√¨nh R¬≤: {score:.4f}" if not pd.isna(score) else "M√¥ h√¨nh R¬≤: n/a"

            # Update UI in main thread
            root.after(0, lambda: [
                text_result.delete('1.0', tk.END),
                text_result.insert(tk.END, result_text),
                update_prediction_chart(df, product, last, pred, month_input, months_to_predict),
                progress.destroy(),
                btn_predict.config(state=tk.NORMAL)
            ])

        except Exception as e:
            root.after(0, lambda: [
                progress.destroy(),
                btn_predict.config(state=tk.NORMAL),
                show_error(f"L·ªói khi d·ª± ƒëo√°n: {str(e)}")
            ])

    # Run prediction in separate thread
    threading.Thread(target=prediction_worker, daemon=True).start()

def update_prediction_chart(df, product, last, pred, target_month, months_to_predict):
    """Update the prediction chart with new data"""
    # Clear old chart
    for w in frame_chart_ml.winfo_children():
        w.destroy()

    # Create new chart
    fig, ax = plt.subplots(figsize=(10, 6))

    # Convert thang to datetime for plotting
    df['thang_dt'] = pd.to_datetime(df['thang'])

    # Plot historical data
    ax.plot(df['thang_dt'], df['doanhso_thang'], marker='o', label='Th·ª±c t·∫ø', linewidth=2)

    # Calculate position for prediction point
    start_date = df['thang_dt'].min()
    prediction_date = start_date + pd.DateOffset(months=months_to_predict)

    # Add prediction point
    ax.plot(prediction_date, pred, 'ro', markersize=8, label='D·ª± ƒëo√°n')

    # Add a line connecting the last data point to the prediction
    last_date = df['thang_dt'].iloc[-1]
    ax.plot([last_date, prediction_date], [last, pred], 'r--', alpha=0.7, linewidth=2)

    # Format x-axis to handle potentially distant dates
    ax.set_xlim(df['thang_dt'].min() - pd.DateOffset(months=1),
                prediction_date + pd.DateOffset(months=1))

    # Format dates on x-axis for better readability
    ax.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))
    ax.xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator(interval=max(1, len(df) // 6)))

    ax.set_title(f'{product} - D·ª± ƒëo√°n th√°ng {target_month}', fontsize=14)
    ax.set_xlabel('Th√°ng', fontsize=12)
    ax.set_ylabel('Doanh s·ªë th√°ng', fontsize=12)
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Rotate x-axis labels for better readability
    plt.xticks(rotation=45)
    plt.tight_layout()

    # Display chart in GUI
    canvas = FigureCanvasTkAgg(fig, master=frame_chart_ml)
    canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    canvas.draw()

    # Store references
    frame_chart_ml.canvas_fig = fig
    frame_chart_ml.canvas_obj = canvas
    current_fig = fig

def load_csvs():
    global processed_df
    files = filedialog.askopenfilenames(title="Ch·ªçn c√°c file CSV", filetypes=[("CSV Files", "*.csv")])
    if not files:
        return
    # Preprocess files function needs to be implemented
    # For now, we'll use the existing import function
    action_import_files()

def load_from_db():
    global processed_df, DB_FILES
    conn = None

    try:
        if not DB_FILES or not all(os.path.exists(db_file) for db_file in DB_FILES):
            show_error("Ch∆∞a ch·ªçn file CSDL")
            return

        all_data = []

        for db_file in DB_FILES:
            try:
                conn = sqlite3.connect(db_file)
                cursor = conn.cursor()

                # L·∫•y danh s√°ch t·∫•t c·∫£ c√°c b·∫£ng
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                tables = [table[0] for table in cursor.fetchall()]

                for table in tables:
                    try:
                        # Ki·ªÉm tra xem b·∫£ng c√≥ c√°c c·ªôt c·∫ßn thi·∫øt kh√¥ng
                        cursor.execute(f"PRAGMA table_info({table})")
                        columns = [col[1] for col in cursor.fetchall()]

                        # Use normalized column names for comparison
                        normalized_columns = [_normalize_colname(col) for col in columns]
                        required_columns = ["ten_san_pham", "da_ban", "ngay_crawl", "link"]
                        has_required = all(col in normalized_columns for col in required_columns)

                        if has_required:
                            # L·∫•y d·ªØ li·ªáu t·ª´ b·∫£ng
                            df_table = pd.read_sql_query(f"SELECT * FROM {table}", conn)

                            # Normalize column names in the dataframe
                            col_map = {col: _normalize_colname(col) for col in df_table.columns}
                            df_table.rename(columns=col_map, inplace=True)

                            all_data.append(df_table)

                    except Exception as e:
                        print(f"L·ªói khi ƒë·ªçc b·∫£ng {table}: {e}")
                        continue

            except Exception as e:
                show_error(f"L·ªói khi k·∫øt n·ªëi CSDL {db_file}: {str(e)}")
                continue
            finally:
                if conn:
                    conn.close()

        if not all_data:
            show_error("Kh√¥ng t√¨m th·∫•y b·∫£ng n√†o c√≥ d·ªØ li·ªáu ph√π h·ª£p")
            return

        # G·ªôp t·∫•t c·∫£ d·ªØ li·ªáu t·ª´ c√°c b·∫£ng
        df_combined = pd.concat(all_data, ignore_index=True)

        # X·ª≠ l√Ω d·ªØ li·ªáu - thay ƒë·ªïi t·ª´ tu·∫ßn sang th√°ng
        df_combined["ngay_crawl"] = pd.to_datetime(df_combined["ngay_crawl"], errors="coerce")
        df_combined = df_combined.dropna(subset=["ngay_crawl"])
        df_combined["thang"] = df_combined["ngay_crawl"].dt.strftime("%Y-%m")  # ƒê·ªãnh d·∫°ng nƒÉm-th√°ng
        df_combined["sanpham_id"] = df_combined["link"].apply(extract_id)

        # Nh√≥m d·ªØ li·ªáu theo th√°ng
        agg = (
            df_combined.groupby(["sanpham_id", "ten_san_pham", "thang"])
            .agg({
                "da_ban": "max",
                "gia": "mean"
            })
            .reset_index()
        )

        agg["doanhso_thang"] = agg.groupby("sanpham_id")["da_ban"].diff().fillna(agg["da_ban"])

        processed_df = agg

        # C·∫≠p nh·∫≠t list s·∫£n ph·∫©m
        listbox_products.delete(0, tk.END)
        for sp in processed_df["ten_san_pham"].unique():
            listbox_products.insert(tk.END, sp)

        show_message(f"ƒê√£ t·∫£i d·ªØ li·ªáu t·ª´ {len(DB_FILES)} CSDL th√†nh c√¥ng")

    except Exception as e:
        show_error(f"L·ªói khi t·∫£i d·ªØ li·ªáu t·ª´ CSDL: {str(e)}")

def load_data_ml():
    # H·ªèi ng∆∞·ªùi d√πng mu·ªën t·∫£i t·ª´ CSV hay t·ª´ CSDL
    choice = messagebox.askquestion("Ch·ªçn ngu·ªìn d·ªØ li·ªáu",
                                    "B·∫°n mu·ªën t·∫£i d·ªØ li·ªáu t·ª´ file CSV hay t·ª´ CSDL hi·ªán t·∫°i?",
                                    icon='question',
                                    type='yesno',
                                    default='yes',
                                    detail='Ch·ªçn Yes ƒë·ªÉ t·∫£i t·ª´ CSV, No ƒë·ªÉ t·∫£i t·ª´ CSDL')

    if choice == 'yes':
        load_csvs()
    else:
        load_from_db()

# Add these helper functions for date processing
def _normalize_colname(col):
    """Normalize column names to lowercase with underscores"""
    if not isinstance(col, str):
        col = str(col)
    col = col.lower()
    col = re.sub(r'[^a-z0-9]+', '_', col)
    return col


def _normalize_vietnamese_text(text):
    """Normalize Vietnamese text by removing diacritics"""
    if not isinstance(text, str):
        return text
    # Normalize unicode characters and remove diacritics
    text = unicodedata.normalize('NFD', text)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    return text.lower()


def _parse_date_flexible(date_str):
    """Try to parse date from multiple formats"""
    if not isinstance(date_str, str):
        return None

    formats = [
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%d",
        "%d/%m/%Y %H:%M:%S",
        "%d/%m/%Y",
        "%m/%d/%Y %H:%M:%S",
        "%m/%d/%Y",
    ]

    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    return None

def extract_date_from_url(url):
    """Try to extract date from URL if present"""
    if not isinstance(url, str):
        return None

    # Look for date patterns in URL
    patterns = [
        r'/(\d{4})/(\d{2})/(\d{2})/',
        r'(\d{4})-(\d{2})-(\d{2})',
    ]

    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            year, month, day = map(int, match.groups())
            try:
                return datetime(year, month, day)
            except ValueError:
                continue
    return None

# Th√™m n√∫t l√†m m·ªõi d·ªØ li·ªáu
def refresh_data():
    cap_nhat_bang()
    cap_nhat_cot()
    if df_global is not None and not df_global.empty:
        hien_thi_preview(df_global)
    show_message("ƒê√£ l√†m m·ªõi d·ªØ li·ªáu")


# ---------------- New functions for file management ----------------
def clear_imported_files():
    global df_global
    if not listbox_files.size():
        show_message("Kh√¥ng c√≥ file n√†o ƒë·ªÉ x√≥a")
        return

    if messagebox.askyesno("X√°c nh·∫≠n", "B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën x√≥a t·∫•t c·∫£ file ƒë√£ import?"):
        listbox_files.delete(0, tk.END)
        df_global = pd.DataFrame()
        show_message("ƒê√£ x√≥a t·∫•t c·∫£ file import v√† l√†m tr·ªëng b·ªô nh·ªõ")


def delete_selected_file():
    selected = listbox_files.curselection()
    if not selected:
        show_error("Vui l√≤ng ch·ªçn m·ªôt file ƒë·ªÉ x√≥a")
        return

    if messagebox.askyesno("X√°c nh·∫≠n", "B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën x√≥a file ƒë√£ ch·ªçn?"):
        listbox_files.delete(selected)
        show_message("ƒê√£ x√≥a file ƒë√£ ch·ªçn kh·ªèi danh s√°ch")


def clear_sql():
    text_sql.delete('1.0', tk.END)


def update_product_list(*args):
    search_term = entry_search_ml.get().lower()
    listbox_products.delete(0, tk.END)
    if processed_df is not None and not processed_df.empty and 'ten_san_pham' in processed_df.columns:
        products = processed_df['ten_san_pham'].unique()
        for p in products:
            if pd.notna(p) and search_term in str(p).lower():
                listbox_products.insert(tk.END, p)


# ---------------- New function to handle table selection ----------------
def on_table_selected(event):
    """X·ª≠ l√Ω s·ª± ki·ªán khi ch·ªçn b·∫£ng t·ª´ combobox"""
    selected_table = combo_table.get()
    if not selected_table or "::" not in selected_table:
        return

    # L·∫•y t√™n database v√† t√™n b·∫£ng
    db_name, table_name = selected_table.split("::", 1)

    # T√¨m ƒë∆∞·ªùng d·∫´n database
    db_path = None
    for db_file in DB_FILES:
        if os.path.basename(db_file) == db_name:
            db_path = db_file
            break

    if not db_path:
        show_error(f"Kh√¥ng t√¨m th·∫•y database: {db_name}")
        return

    try:
        # K·∫øt n·ªëi database v√† ƒë·ªçc d·ªØ li·ªáu
        conn = sqlite3.connect(db_path)
        df = pd.read_sql_query(f'SELECT * FROM "{table_name}"', conn)
        conn.close()

        # Hi·ªÉn th·ªã d·ªØ li·ªáu trong ph·∫ßn xem tr∆∞·ªõc
        hien_thi_preview(df)

        # C·∫≠p nh·∫≠t danh s√°ch s·∫£n ph·∫©m trong tab H·ªçc m√°y
        listbox_products.delete(0, tk.END)

        # T√¨m c·ªôt ch·ª©a t√™n s·∫£n ph·∫©m (c√≥ th·ªÉ c√≥ c√°c t√™n kh√°c nhau)
        product_col = None
        possible_names = ['T√™n s·∫£n ph·∫©m', 'ten_san_pham', 'product_name', 'name', 'title']

        for col in possible_names:
            if col in df.columns:
                product_col = col
                break

        if product_col:
            products = df[product_col].dropna().unique()
            for p in products:
                listbox_products.insert(tk.END, p)
        else:
            show_message("Kh√¥ng t√¨m th·∫•y c·ªôt t√™n s·∫£n ph·∫©m trong b·∫£ng n√†y")

    except Exception as e:
        show_error(f"L·ªói khi ƒë·ªçc b·∫£ng: {str(e)}")


# --Giao di·ªán--
root = tk.Tk()
root.title(APP_TITLE)
root.geometry('1400x900')
root.configure(bg='#f5f5f5')

# T·∫°o style cho giao di·ªán
style = ttk.Style()
style.theme_use('clam')

# C·∫•u h√¨nh m√†u s·∫Øc chung
BG_COLOR = '#ffffff'  # M√†u n·ªÅn tr·∫Øng
FG_COLOR = '#2d2d2d'  # M√†u ch·ªØ t·ªëi
ACCENT_COLOR = '#2b579a'  # M√†u xanh
HOVER_COLOR = '#f3f3f3'  # M√†u n·ªÅn khi hover
RED_COLOR = '#dc3545'  # M√†u ƒë·ªè cho n√∫t x√≥a
RED_HOVER = '#c82333'  # M√†u ƒë·ªè khi hover

# C·∫•u h√¨nh style
style.configure('TFrame', background=BG_COLOR)
style.configure('TLabel', background=BG_COLOR, foreground=FG_COLOR, font=('Segoe UI', 9))
style.configure('TNotebook', background=BG_COLOR)
style.configure('TNotebook.Tab', font=('Segoe UI', 9, 'bold'), padding=[10, 5])

# Style cho c√°c n√∫t
style.configure('TButton',
                font=('Segoe UI', 9, 'bold'),
                borderwidth=1,
                focusthickness=0,
                padding=(14, 8),
                anchor="center")
style.map('TButton',
          background=[('active', HOVER_COLOR), ('pressed', '#e1e1e1')],
          relief=[('pressed', 'sunken'), ('!pressed', 'flat')])

# Style cho n√∫t ch√≠nh (n·ªïi b·∫≠t h∆°n)
style.configure('Accent.TButton',
                background=ACCENT_COLOR,
                foreground='white')
style.map('Accent.TButton',
          background=[('active', '#3a6bb0'), ('pressed', '#1e4a7e')])

# Style cho n√∫t x√≥a
style.configure('Danger.TButton',
                background=RED_COLOR,
                foreground='white')
style.map('Danger.TButton',
          background=[('active', RED_HOVER), ('pressed', '#a71e2d')])

notebook = ttk.Notebook(root)
notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

# --- Tab SQL & Chart ---
tab_sql = ttk.Frame(notebook)
notebook.add(tab_sql, text='üìä SQL & Tr·ª±c quan')

# top controls
top_frame = tk.Frame(tab_sql, bg=BG_COLOR)
top_frame.pack(fill=tk.X, padx=10, pady=10)

tk.Label(top_frame, text='CSDL:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)

# Thay th·∫ø entry_db b·∫±ng listbox_dbs v√† c√°c n√∫t
frame_dbs = tk.Frame(top_frame, bg=BG_COLOR)
frame_dbs.pack(side=tk.LEFT, padx=6)

listbox_dbs = tk.Listbox(frame_dbs, width=60, height=3, bg='white', fg=FG_COLOR, font=('Segoe UI', 9), relief='solid',
                         bd=1)
listbox_dbs.pack(side=tk.LEFT, fill=tk.X, expand=True)

scrollbar_dbs = ttk.Scrollbar(frame_dbs, orient=tk.VERTICAL, command=listbox_dbs.yview)
scrollbar_dbs.pack(side=tk.RIGHT, fill=tk.Y)
listbox_dbs.config(yscrollcommand=scrollbar_dbs.set)

btn_add_db = ttk.Button(top_frame, text='‚ûï Th√™m CSDL', command=add_db_files)
btn_add_db.pack(side=tk.LEFT, padx=2)

btn_remove_db = ttk.Button(top_frame, text='‚ûñ X√≥a CSDL', command=remove_db_file, style="Danger.TButton")
btn_remove_db.pack(side=tk.LEFT, padx=2)

ttk.Button(top_frame, text='üï∑Ô∏è Crawl Tiki', command=action_crawl_dialog, style="Accent.TButton").pack(side=tk.LEFT,
                                                                                                      padx=2)
ttk.Button(top_frame, text='üìÅ Import files', command=action_import_files).pack(side=tk.LEFT, padx=2)
ttk.Button(top_frame, text='üìä Export CSV', command=export_current_csv).pack(side=tk.LEFT, padx=2)
ttk.Button(top_frame, text='üìä Export Excel', command=export_current_excel).pack(side=tk.LEFT, padx=2)
ttk.Button(top_frame, text='üìÑ Export PDF', command=export_report_pdf).pack(side=tk.LEFT, padx=2)
ttk.Button(top_frame, text='üîÑ L√†m m·ªõi', command=refresh_data).pack(side=tk.RIGHT, padx=2)

# SQL area
frame_sql = tk.Frame(tab_sql, bg=BG_COLOR)
frame_sql.pack(fill=tk.X, padx=10, pady=10)

tk.Label(frame_sql, text='SQL Query:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)
text_sql = tk.Text(frame_sql, height=4, width=70, bg='white', fg=FG_COLOR,
                   insertbackground=FG_COLOR, wrap=tk.WORD, font=('Consolas', 10),
                   relief='solid', bd=1)
text_sql.pack(side=tk.LEFT, padx=6, fill=tk.X, expand=True)

ttk.Button(frame_sql, text='‚ùå X√≥a', command=clear_sql, style="Danger.TButton").pack(side=tk.LEFT, padx=6)

frame_ctrl = tk.Frame(tab_sql, bg=BG_COLOR)
frame_ctrl.pack(fill=tk.X, padx=10, pady=10)

tk.Label(frame_ctrl, text='B·∫£ng:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)
combo_table = ttk.Combobox(frame_ctrl, width=25, postcommand=cap_nhat_bang, font=('Segoe UI', 9))
combo_table.pack(side=tk.LEFT, padx=6)
# Th√™m s·ª± ki·ªán khi ch·ªçn b·∫£ng
combo_table.bind('<<ComboboxSelected>>', on_table_selected)

tk.Label(frame_ctrl, text='C·ªôt X:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)
combo_x = ttk.Combobox(frame_ctrl, width=20, font=('Segoe UI', 9))
combo_x.pack(side=tk.LEFT, padx=6)

tk.Label(frame_ctrl, text='C·ªôt Y:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)
combo_y = ttk.Combobox(frame_ctrl, width=20, font=('Segoe UI', 9))
combo_y.pack(side=tk.LEFT, padx=6)

tk.Label(frame_ctrl, text='Lo·∫°i bi·ªÉu ƒë·ªì:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)
combo_chart = ttk.Combobox(frame_ctrl, values=['Bar', 'Line', 'Pie', 'Scatter'], width=12, font=('Segoe UI', 9))
combo_chart.set('Bar')
combo_chart.pack(side=tk.LEFT, padx=6)

ttk.Button(frame_ctrl, text='üìä Ch·∫°y & V·∫Ω', command=chay_sql_va_ve, style="Accent.TButton").pack(side=tk.LEFT, padx=6)
ttk.Button(frame_ctrl, text='üíæ L∆∞u ·∫£nh', command=save_chart_image).pack(side=tk.LEFT, padx=6)
ttk.Button(frame_ctrl, text='üìà Top 10 SP', command=analyze_top_products, style="Accent.TButton").pack(side=tk.LEFT, padx=6)
ttk.Button(frame_ctrl, text='üìÖ So s√°nh ng√†y', command=compare_by_date).pack(side=tk.LEFT, padx=6)
ttk.Button(frame_ctrl, text='üîç Ph√≥ng to', command=phong_to).pack(side=tk.LEFT, padx=6)

# file list + preview
listbox_frame = tk.Frame(tab_sql, bg=BG_COLOR)
listbox_frame.pack(fill=tk.X, padx=10, pady=5)

# T·∫°o frame ch·ª©a ti√™u ƒë·ªÅ v√† n√∫t x√≥a files n·∫±m ngang h√†ng
file_header_frame = tk.Frame(listbox_frame, bg=BG_COLOR)
file_header_frame.pack(fill=tk.X)

# Label ti√™u ƒë·ªÅ b√°m tr√°i
tk.Label(
    file_header_frame, text='üìÇ C√°c file ƒë√£ import:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 10, 'bold')
).pack(side=tk.LEFT, anchor="w", padx=(2, 0))

# Frame ch·ª©a listbox v√† c√°c n√∫t
file_list_frame = tk.Frame(listbox_frame, bg=BG_COLOR)
file_list_frame.pack(fill=tk.X, pady=5)

# Listbox v·ªõi selectmode EXTENDED ƒë·ªÉ ch·ªçn nhi·ªÅu file

listbox_files = tk.Listbox(

    file_list_frame, height=4, bg='white', fg=FG_COLOR, font=('Segoe UI', 9), relief='solid', bd=1,
    selectmode=tk.EXTENDED
)
listbox_files.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 5))

# Frame ch·ª©a c√°c n√∫t b√™n ph·∫£i
button_frame = tk.Frame(file_list_frame, bg=BG_COLOR)
button_frame.pack(side=tk.RIGHT, fill=tk.Y)

# N√∫t x√≥a file ƒë√£ ch·ªçn
btn_delete_selected = ttk.Button(
    button_frame, text='üóëÔ∏è X√≥a file ƒë√£ ch·ªçn', command=delete_selected_file, style="Danger.TButton"
)
btn_delete_selected.pack(side=tk.TOP, fill=tk.X, pady=(0, 5))

# N√∫t x√≥a t·∫•t c·∫£ files
btn_clear = ttk.Button(
    button_frame, text='‚ùå X√≥a t·∫•t c·∫£', command=clear_imported_files, style="Danger.TButton"
)
btn_clear.pack(side=tk.TOP, fill=tk.X)

# Frame preview v·ªõi label
preview_frame = tk.Frame(tab_sql, bg=BG_COLOR)
preview_frame.pack(fill=tk.BOTH, expand=False, padx=10, pady=10)

# T·∫°o frame ch·ª©a cho ti√™u ƒë·ªÅ v√† thanh t√¨m ki·∫øm
header_frame = tk.Frame(preview_frame, bg=BG_COLOR)
header_frame.pack(fill=tk.X, pady=(0, 5))

# Nh√£n "Xem tr∆∞·ªõc d·ªØ li·ªáu" b√™n tr√°i
tk.Label(header_frame, text='Xem tr∆∞·ªõc d·ªØ li·ªáu:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)

# Frame t√¨m ki·∫øm b√™n ph·∫£i
search_frame = tk.Frame(header_frame, bg=BG_COLOR)
search_frame.pack(side=tk.LEFT)

# C√°c th√†nh ph·∫ßn t√¨m ki·∫øm
tk.Label(search_frame, text='T√¨m s·∫£n ph·∫©m:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)
entry_search_sql = ttk.Entry(search_frame, width=20, font=('Segoe UI', 9))
entry_search_sql.pack(side=tk.LEFT, padx=6)
ttk.Button(search_frame, text='üîç T√¨m', command=search_product_sql).pack(side=tk.LEFT, padx=2)

# Khung xem tr∆∞·ªõc d·ªØ li·ªáu
frame_preview = tk.Frame(preview_frame, relief='solid', borderwidth=1, height=220, bg='white')
frame_preview.pack(fill=tk.BOTH, pady=5, expand=True)

# Frame chart v·ªõi label
chart_frame = tk.Frame(tab_sql, bg=BG_COLOR)
chart_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

tk.Label(chart_frame, text='Bi·ªÉu ƒë·ªì:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(anchor='w')
frame_chart = tk.Frame(chart_frame, bg='white', height=360, relief='solid', bd=1)
frame_chart.pack(fill=tk.BOTH, pady=5, expand=True)

# bottom filter in SQL tab
bottom_filter = tk.Frame(tab_sql, bg=BG_COLOR)
bottom_filter.pack(fill=tk.X, padx=10, pady=10)

tk.Label(bottom_filter, text='L·ªçc d·ªØ li·ªáu:', bg=BG_COLOR, fg=FG_COLOR, font=('Segoe UI', 9)).pack(side=tk.LEFT)
entry_filter = ttk.Entry(bottom_filter, width=30, font=('Segoe UI', 9))
entry_filter.pack(side=tk.LEFT, padx=6)
ttk.Button(bottom_filter, text='üîç √Åp d·ª•ng b·ªô l·ªçc', command=filter_preview).pack(side=tk.LEFT, padx=6)
ttk.Button(bottom_filter, text='‚ùå X√≥a b·ªô l·ªçc',
           command=lambda: [entry_filter.delete(0, tk.END), hien_thi_preview(df_global)],
           style="Danger.TButton").pack(side=tk.LEFT, padx=6)

# =========== TAB H·ªåC M√ÅY ===========
tab_ml = ttk.Frame(notebook)
notebook.add(tab_ml, text="ü§ñ H·ªçc m√°y")

# Frame b√™n tr√°i
frame_left = ttk.Frame(tab_ml, width=300)
frame_left.pack(side=tk.LEFT, fill=tk.Y, padx=5, pady=5)

# Ti√™u ƒë·ªÅ
ttk.Label(frame_left, text="D·ª∞ ƒêO√ÅN DOANH S·ªê", font=("Arial", 12, "bold")).pack(pady=10)

# √î t√¨m ki·∫øm
ttk.Label(frame_left, text="T√¨m ki·∫øm s·∫£n ph·∫©m:").pack(anchor=tk.W, pady=(10, 5))
entry_search_ml = ttk.Entry(frame_left)
entry_search_ml.pack(fill=tk.X, padx=5, pady=5)
entry_search_ml.bind("<KeyRelease>", search_product_ml)

# Danh s√°ch s·∫£n ph·∫©m
ttk.Label(frame_left, text="Danh s√°ch s·∫£n ph·∫©m:").pack(anchor=tk.W, pady=(10, 5))
listbox_products = tk.Listbox(frame_left, height=15)
listbox_products.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

# Frame cho th√°ng d·ª± ƒëo√°n
frame_predict_month = ttk.Frame(frame_left)
frame_predict_month.pack(fill=tk.X, pady=5)

ttk.Label(frame_predict_month, text="Th√°ng d·ª± ƒëo√°n (MM/YYYY):").pack(anchor=tk.W)
entry_predict_month = ttk.Entry(frame_predict_month)
entry_predict_month.pack(fill=tk.X, pady=2)
entry_predict_month.insert(0, datetime.now().strftime("%m/%Y"))

# Th√™m c√°c th√†nh ph·∫ßn cho ph∆∞∆°ng ph√°p d·ª± ƒëo√°n
frame_methods = ttk.Frame(frame_left)
frame_methods.pack(fill=tk.X, pady=5)

ttk.Label(frame_methods, text="Ph∆∞∆°ng ph√°p:").pack(anchor=tk.W)
combo_ml_method = ttk.Combobox(frame_methods, values=["Linear Regression", "Moving Average"], state="readonly")
combo_ml_method.set("Linear Regression")
combo_ml_method.pack(fill=tk.X, pady=2)

ttk.Label(frame_methods, text="C·ª≠a s·ªï MA:").pack(anchor=tk.W)
entry_ma_window = ttk.Entry(frame_methods)
entry_ma_window.insert(0, "3")
entry_ma_window.pack(fill=tk.X, pady=2)

# N√∫t chu·∫©n h√≥a d·ªØ li·ªáu
btn_preprocess = ttk.Button(frame_left, text="üîÑ Chu·∫©n h√≥a d·ªØ li·ªáu", command=prepare_processed_from_df_global)
btn_preprocess.pack(fill=tk.X, pady=5)

# N√∫t d·ª± ƒëo√°n
btn_predict = ttk.Button(frame_left, text="üîÆ D·ª± ƒëo√°n", command=predict_next_month)
btn_predict.pack(fill=tk.X, pady=5)

# Frame b√™n ph·∫£i
frame_right = ttk.Frame(tab_ml)
frame_right.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=5, pady=5)

# K·∫øt qu·∫£ d·ª± ƒëo√°n
ttk.Label(frame_right, text="K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN", font=("Arial", 12, "bold")).pack(pady=10)
text_result = tk.Text(frame_right, height=8, wrap=tk.WORD)
text_result.pack(fill=tk.X, padx=5, pady=5)

# Bi·ªÉu ƒë·ªì
ttk.Label(frame_right, text="BI·ªÇU ƒê·ªí DOANH S·ªê", font=("Arial", 12, "bold")).pack(pady=(20, 5))
frame_chart_ml = ttk.Frame(frame_right, height=300)
frame_chart_ml.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)

# Th√™m h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
instruction_text = """
H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:
1. Ch·ªçn b·∫£ng d·ªØ li·ªáu t·ª´ tab SQL & Tr·ª±c quan
2. Nh·∫•n 'Chu·∫©n h√≥a d·ªØ li·ªáu' ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu
3. T√¨m ki·∫øm v√† ch·ªçn s·∫£n ph·∫©m c·∫ßn d·ª± ƒëo√°n
4. Ch·ªçn ph∆∞∆°ng ph√°p d·ª± ƒëo√°n v√† nh·∫•n 'D·ª± ƒëo√°n'
"""
instruction_label = ttk.Label(frame_left, text=instruction_text, justify=tk.LEFT)
instruction_label.pack(fill=tk.X, padx=5, pady=10)

# initialize
ensure_db_files()
cap_nhat_bang()
cap_nhat_cot_from_table()

# Ch·∫°y ·ª©ng d·ª•ng
root.mainloop()
